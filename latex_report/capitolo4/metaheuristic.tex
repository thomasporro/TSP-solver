While the heuristic approach seen before was strictly specific to the TSP problem, the concept of metaheuristic is quite different. Their procedure is problem-independent and does not take advantage of any specificity of the problem. Generally, these techniques are not greedy and can accept a temporary deterioration of the solution in order to have a bigger search space in which to find a better solution.

In this section, some of them will be used such as the variable neighborhood search and the tabu search.

\subsection{Variable Neighborhood Search}
\label{sec:VNS}
The variable neighborhood search (VNS) is the first metaheuristic approach presented. Its main purpose is to try to escape from a local optimal of the solution aiming to find the optimal solution of the problem. 

The instance of the problem can be seen as a function with its local minima, local maxima, and so on. During the utilization of some heuristic techniques, it is possible that the process remains stuck in a sub-optimal area. The way in which it tries to escape from this region is done by changing the \textit{neighborhood} of the solution: some data are modified and then a new minimum is searched.

In this report, the adjustment of the neighborhood is performed by a perturbation phase in which is applied a $k$-opt kick. This change is performed by selecting randomly a $k$ set of edges and then replacing them with others in order to obtain a poor solution. In particular, the procedure done is the following: a $2$-opt refining is applied to a reference solution, once the minimum is reached a kick is given to the solution to worsening the solution. Then the $2$-opt refining approach is used again to find a new minimum. In my implementation are implemented three perturbations: 3, 5, and 7. An example of implementation can be seen in Algorithm \ref{algo:vns}.

\begin{algorithm}
	\caption{VNS}\label{algo:vns}
	\begin{algorithmic}[1]
		\Require $G=(V,E)$,$ c:E\rightarrow \Re^+, k, global\_timelimit$
		\Ensure $z\text{ hopefully good solution}$
		\State $z_{curr}$ $\gets$ $z$ $\gets$ *built solution using an heuristc*
		\State $best\_cost$ $\gets$ cost($z$)
		\State cycles $\gets$ $0$
		\While{$time\_elapsed<global\_timelimit$}
			\State $z_{curr}$ $\gets$ \textsc{2-opt($z_{curr}$)}
			\If{cost($z_{curr}$) $< best\_cost$}
				\State z $\gets$ $z_{curr}$
				\State $best\_cost$ $\gets$ cost($z_{curr}$)
			\EndIf
		\State *Bigger the value of cycles bigger the kick*
		\State $z_{curr}$ $\gets$ \textsc{k-kick($cycles$)}
		\State cycles $\gets$ cycles$+1$
		\EndWhile
		\State \Return $z$
	\end{algorithmic}
\end{algorithm}


\subsection{Tabu search}
\label{sec:tabu-search}
The tabu search is the second metaheuristic presented in this report. It is a method to improve the local search and avoid falling back in a previous local minimum. To do that the concept of tabu is introduced: a set of banned solutions prevents the algorithm to return an already visited result.

In this implementation of the tabu search the refining phase is performed by a 2-opt move as it happened in section \ref{sec:VNS}, then the method to escape from this minimum is to perform a kick like as the previous section. The main difference is that during the VNS is possible to fall again and again in the previous solution, using the tabu search is not possible. 

The worsening move is performed by swapping two non-consecutive edges, then they are declared as tabu: they cannot be swapped for a while. This process precludes the possibility of falling into a cycle of deterioration-recover, where to final solution is always the same. This algorithm will continuously worsen the solution until a non-tabu move is performed.

The way in which this method is implemented is the following: each time a worsening action is performed the nodes selected are declared as tabu and the edges connected with them cannot be changed by any improving moves. If each time this action has been performed the list of tabu nodes becomes so large that no more moves are allowed. To avoid this case it is introduced a new variable called $tenure$, its main idea is to limit how many times a tabu is valid.

To do that we declare a node tabu (for example $i$) by inserting into an array the iteration number $h$, so $tabu\_nodes[i] = h$. This constraint will last for a $tenure$ number of times, following this rule:

\begin{equation}
	iteration\_number - tabu[i] \le tenure
\end{equation}

A good choice of $tenure$ is crucial to allow the algorithm to perform adequately. The best decision is to make it variable regarding the number of iterations already completed. In algorithm \ref{algo:tabu-search} can be seen the proceeding of this method.

\begin{algorithm}
	\caption{Tabu search}\label{algo:tabu-search}
	\begin{algorithmic}[1]
		\Require $G=(V,E)$,$ c:E\rightarrow \Re^+, k, global\_timelimit$
		\Ensure $z\text{ hopefully good solution}$
		\State $z_{curr}$ $\gets$ $z$ $\gets$ *built solution using an heuristc*
		\State $best\_cost$ $\gets$ cost($z$)
		\State $iteration\_counter \gets 1$
		\While{$time\_elapsed<global\_timelimit$}
			\State *Performs a 2-opt refining applying the constaraint described in section \ref{sec:tabu-search}. The iteration counter is increased each time a move is performed. If no moves are allowed this method does nothing*
			\State $z_{new}$ $\gets$ \textsc{tabu-2-opt($z_{curr}, tabu, tenure, iteration\_counter$)}
			\If{cost($z_{curr}$) $< best\_cost$}
				\State z $\gets$ $z_{curr}$
				\State $best\_cost$ $\gets$ cost($z_{curr}$)
			\EndIf
			\State $first\_node \gets RANDOM(|V|)$
			\State $second\_node \gets RANDOM(|V|)$
			\State $tabu[first\_node] \gets iteration\_counter$
			\State $tabu[second\_node] \gets iteration\_counter$
			\State $z_{curr} \gets $ \textsc{2-kick($first\_node, second\_node$)}
			\State $iteration\_counter \gets iteration\_counter+1$
		\EndWhile
		\State \Return $z$
	\end{algorithmic}
\end{algorithm}

\subsection{Genetic algorithms}