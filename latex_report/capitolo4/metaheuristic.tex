While the heuristic approach seen before was strictly specific to the TSP problem, the concept of metaheuristic is quite different. Its procedure is problem-independent and it does not take advantage of any specificity of the problem. Generally, it is not greedy and it can accept a temporary deterioration of the solution in order to have a bigger search space in which to find a better solution.

In this section, the variable neighborhood search and the tabu search are used.

\subsection{Variable Neighborhood Search}
\label{sec:VNS}
The variable neighborhood search (VNS) is the first metaheuristic approach presented. Its main purpose is to try to escape from a local optima aiming to find the optimal solution of the problem. 

The instance of the problem can be seen as a function with its local minima, local maxima, and so on. During the utilization of some heuristic techniques, it is possible that the process remains stuck in a sub-optimal area. The way in which it tries to escape from this region is done by changing the \textit{neighborhood} of the solution: some data are modified and then a new minimum is searched.

In this report, the adjustment of the neighborhood is performed by a perturbation phase in which is applied a $k$-opt kick. This change is performed by selecting randomly a $k$ set of edges and then replacing them with others in order to obtain a poor solution. In particular, the procedure done is the following: a $2$-opt refining is applied to a reference solution, and when the minimum is reached a kick is given to the solution to worsening the solution. Then, the $2$-opt refining approach is used again to find a new minimum. In my implementation, three perturbations are implemented: 3, 5, and 7. An example of implementation can be seen in Algorithm \ref{algo:vns}.

\begin{algorithm}
	\caption{VNS}\label{algo:vns}
	\begin{algorithmic}[1]
		\Require $G=(V,E)$,$ c:E\rightarrow \Re^+, k, global\_timelimit$
		\Ensure $z\text{ hopefully good solution}$
		\State $z_{curr}$ $\gets$ $z$ $\gets$ *built solution using an heuristc*
		\State $best\_cost$ $\gets$ cost($z$)
		\State cycles $\gets$ $0$
		\While{$time\_elapsed<global\_timelimit$}
			\State $z_{curr}$ $\gets$ \textsc{2-opt($z_{curr}$)}
			\If{cost($z_{curr}$) $< best\_cost$}
				\State z $\gets$ $z_{curr}$
				\State $best\_cost$ $\gets$ cost($z_{curr}$)
			\EndIf
		\State *Bigger the value of cycles bigger the kick*
		\State $z_{curr}$ $\gets$ \textsc{k-kick($cycles$)}
		\State cycles $\gets$ cycles$+1$
		\EndWhile
		\State \Return $z$
	\end{algorithmic}
\end{algorithm}


\subsection{Tabu search}
\label{sec:tabu-search}
The tabu search is the second metaheuristic presented in this report. This method improves the local search and avoids falling back in a previous local minimum. To do that the concept of tabu is introduced: a set of banned solutions for preventing the algorithm to return an already visited result.

In this implementation of the tabu search the refining phase is performed by a 2-opt move as it happened in section \ref{sec:VNS}. The method for escaping from this minimum is to perform a kick like in the previous section. The main difference is that during the VNS it is possible to fall again and again in the previous solution, while using the tabu search this is not possible. 

The worsening move is performed by swapping two non-consecutive edges and then declaring them as tabu: they cannot be swapped for a while. This process precludes the possibility of falling into a cycle of deterioration-recover, where the final solution is always the same. This algorithm will continuously worsen the solution until a non-tabu move is performed.

The way in which this method is implemented is the following: each time a worsening action is performed, the nodes selected are declared as tabu and the edges connected with them cannot be changed by any improving moves. If this always happens, the list of tabu nodes becomes so large that no more moves are allowed. To avoid this case, a new variable called $tenure$ is introduced: the main idea is to limit how many times a tabu is valid.

To do that, a node tabu (for example $i$) is declared by inserting into an array the iteration number $h$, so $tabu\_nodes[i] = h$. This constraint will last for a $tenure$ number of times, following this rule:

\begin{equation}
	iteration\_number - tabu[i] \le tenure
\end{equation}

A good choice of $tenure$ is crucial to allow the algorithm to perform adequately. The best decision is to make it variable based on the number of iterations already completed. In algorithm \ref{algo:tabu-search} can be seen the proceeding of this method.

\begin{algorithm}
	\caption{Tabu search}\label{algo:tabu-search}
	\begin{algorithmic}[1]
		\Require $G=(V,E)$,$ c:E\rightarrow \Re^+, k, global\_timelimit$
		\Ensure $z\text{ hopefully good solution}$
		\State $z_{curr}$ $\gets$ $z$ $\gets$ *built solution using an heuristc*
		\State $best\_cost$ $\gets$ cost($z$)
		\State $iteration\_counter \gets 1$
		\While{$time\_elapsed<global\_timelimit$}
			\State *Performs a 2-opt refining applying the constaraint described in section \ref{sec:tabu-search}. The iteration counter is increased each time a move is performed. If no moves are allowed this method does nothing*
			\State $z_{new}$ $\gets$ \textsc{tabu-2-opt($z_{curr}, tabu, tenure, iteration\_counter$)}
			\If{cost($z_{curr}$) $< best\_cost$}
				\State z $\gets$ $z_{curr}$
				\State $best\_cost$ $\gets$ cost($z_{curr}$)
			\EndIf
			\State $first\_node \gets RANDOM(|V|)$
			\State $second\_node \gets RANDOM(|V|)$
			\State $tabu[first\_node] \gets iteration\_counter$
			\State $tabu[second\_node] \gets iteration\_counter$
			\State $z_{curr} \gets $ \textsc{2-kick($first\_node, second\_node$)}
			\State $iteration\_counter \gets iteration\_counter+1$
		\EndWhile
		\State \Return $z$
	\end{algorithmic}
\end{algorithm}

\subsection{Genetic algorithms}
The last algorithm presented is the genetic one. Its main purpose is to generate a good solution to a problem by emulating natural selection. In particular, this evolution process is composed by different phases: reproduction (with recombination), selection, and mutation.

How this algorithm is going to emulate this idea is: each "generation" (or epoch) of individuals is represented by a set of feasible solutions of the TSP problem, and the next generation will be produced using the individuals of the previous epoch. Since it is a simulation of nature, some of the entities must die because they are too weak to survive.

To be able to perform this approach a random population must be constructed. This set is a group of feasible solutions to the TSP problem, but their costs are far from optimal since they are generated randomly.

Each epoch must go through a sequence of phases that are the following:

\begin{itemize}
	\item parent selection: a certain number of pairs of individuals are randomly chosen from the population to be the parents of a child. With the focus to improve the solution cost over time, the individuals with better fitness are advantaged;
	\item offspring generation: for each pair of parents a new child is generated by combining their chromosomes;
	\item population management: to maintain constant the number of elements in the population, a set (equal to the number of new children) is killed. As happened during the parents selection, the group is random but the elements with higher fitness have more probability to die. Noticeably, the individual with the best fitness cannot be killed since it has greater chances to survive in nature;
	\item mutation: a random number of mutations is applied to a random number of elements. As well as the previous point, the champion (individual with the best fitness) is unlikely subject to mutation.
\end{itemize}

This algorithm follows the same path of the previous ones: it is run for some time and then the best solution found over the epochs is returned.

\subsubsection{Implementation details}
\label{sec:implementation-genetic}
A little clarification is given on how this approach is implemented. Until this point, the solution was represented by an array of successors: each index of the array was the node number, and its content was the index of the next node in the cycle. To embrace the concept of chromosomes, a new type of representation is generated: the solution array will contain a sequence of indexes which will be the sequence of nodes in the tour. In this way, the combination of chromosomes is much easier to
do. 

A way to perform this is to select a cutting point in the parents chromosomes and then to choose the first part from one parent and the second one from the other. During this operation, there is the possibility that the second part of the chromosome presents a node already in the first half: in this case, the node is discarded and the merging process continues. Once this operation is finished, the nodes that are not in the child solution (because of the repetition of nodes) are added using the extra-mileage algorithm. This phase is called the fixing phase and even if there is not a corresponding process in nature, it is necessary to have a feasible solution after the generation phase.

The mutation process is not always applied since it is not always present in nature. It is applied only when the difference between the best and the worse fitness is too low. In this way, a possible best solution in the next epochs is generated.

